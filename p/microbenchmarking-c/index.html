<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://bnmoch3.org/favicon.ico?><link rel=icon type=image/png sizes=16x16 href=https://bnmoch3.org/favicon-16x16.png?><link rel=icon type=image/png sizes=32x32 href=https://bnmoch3.org/favicon-32x32.png?><link rel=icon type=image/png sizes=192x192 href=https://bnmoch3.org/android-chrome-192x192.png?><link rel=apple-touch-icon sizes=180x180 href=https://bnmoch3.org/apple-touch-icon.png?><meta name=description content><title>Microbenchmarking: Way more than I set out to know | bnmoch3
</title><link rel=canonical href=https://bnmoch3.org/p/microbenchmarking-c/><meta property="og:url" content="https://bnmoch3.org/p/microbenchmarking-c/"><meta property="og:site_name" content="bnmoch3"><meta property="og:title" content="Microbenchmarking: Way more than I set out to know"><meta property="og:description" content="RDTSC, Out-of-order execution, OS interrupts, cycles, frequency and more."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-25T00:00:00+00:00"><meta property="article:modified_time" content="2023-11-25T00:00:00+00:00"><meta property="article:tag" content="Computer Systems"><link rel=stylesheet href=/assets/combined.min.01980ad4202828eb32272e7b1654f79f3c0022c15b1c932668dff73dffaf7e88.css media=all></head><body class=light><div class=content><header><div class=header><div class=flex><p class=small><a href=/>/home</a></p><p class=small><a href=/about>/about</a></p><p class=small><a href=/posts>/posts</a></p><p class=small><a href=/notes>/notes</a></p><p class=small><a href=/tags>/tags</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>Home</a>
<span class=breadcrumbs-separator>> </span><a href=/posts/>Posts</a>
<span class=breadcrumbs-separator>> </span><a class=breadcrumbs-current href=/p/microbenchmarking-c/>Microbenchmarking: Way more than I set out to know</a></div><div><div class=single-intro-container><h1 class=single-title>Microbenchmarking: Way more than I set out to know</h1><p class=single-readtime><time datetime=2023-11-25T00:00:00+00:00>November 25, 2023</time>
&nbsp; · &nbsp;
16 min read</p></div><div class=single-content><h2 class=heading id=intro>Intro
<a href=#intro>#</a></h2><p>Benchmarking in systems programming is quite a different beast from what I&rsquo;m
used to. My past experience has been with higher level language tooling where I
could get away with ballpark figures for some quick comparison.</p><p>In C & low-level programming though, all of a sudden there&rsquo;s talk of accuracy,
clock precision, kinds of clocks, granularity of the benchmark, cycles spent,
statistical rigor and a whole other bunch of stuff I&rsquo;ve never really put that
much thought into. What&rsquo;s more, there&rsquo;s as much concern for the <em>why</em> as there
is for the <em>how</em>, if not more: is the benchmark even useful, what&rsquo;s its goal, am
I making the correct comparisons, what would the results portend for the overall
system and so on. It&rsquo;s quite easy to end up getting hyperfixated on some piece
of code that doesn&rsquo;t even contribute much to overall runtime or instead
increases performance at the expense of some other critical resource.</p><p>To be fair, the same kind of attention ought to and does carry over to
higher-level development, it just so happens that there&rsquo;s more material and
practitioners concerned with the finer details of benchmarking in systems
programming. Lower level components don&rsquo;t change as much so a lot of the
development effort and expertise tends towards debugging and improving
performance - hence the over-representation.</p><p>So this post details (in a mostly informal manner) all the stuff I picked up
while trying to figure out how to carry out microbenchmarks in C (Linux, Intel
x86-64).</p><h2 class=heading id=measuring-clock-cycles>Measuring clock cycles
<a href=#measuring-clock-cycles>#</a></h2><p>Let&rsquo;s start with measuring cycles - the basic unit of time in a processor within
which some chunk of work is carried out. Intel (64 & IA-32) provides the RDTSC
&ldquo;read timestamp counter&rdquo; instruction for reading the timestamp counter that&rsquo;s
incremented every cycle. From Intel&rsquo;s manual [1], RDTSC is described as follows:</p><blockquote><p>Reads the current value of the processor’s time-stamp counter (a 64-bit MSR)
into the EDX:EAX registers. The EDX register is loaded with the high-order 32
bits of the MSR and the EAX register is loaded with the low-order 32 bits.</p></blockquote><p>As an aside, MSR stands for
<a href=https://en.wikipedia.org/wiki/Model-specific_register>Model specific register</a> -
control registers within the CPU for debugging/monitoring/performance stuff.</p><p>There are two ways to read the timestamp value: via the <code>__rdtsc()</code> gcc compiler
intrinsic, or by writing some inlined assembly as shown below [5]. Using inlined
assembly has to be done carefully since the RDTSC instruction overwrites the EAX
and EDX registers - you don&rsquo;t want to end up with a segmentation fault, or
worse.</p><div class=highlight><pre tabindex=0 style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;stdint.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020></span>
</span></span><span style=display:flex><span><span style=color:#902000>uint64_t</span> <span style=color:#007020;font-weight:700>inline</span> <span style=color:#06287e>rdtsc</span>() {
</span></span><span style=display:flex><span>    <span style=color:#902000>uint32_t</span> <span style=color:#902000>int</span> lo, hi;
</span></span><span style=display:flex><span>    __asm__ <span style=color:#06287e>__volatile__</span>(<span style=color:#4070a0>&#34;rdtsc&#34;</span> <span style=color:#666>:</span> <span style=color:#4070a0>&#34;=a&#34;</span>(lo), <span style=color:#4070a0>&#34;=d&#34;</span>(hi));
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>return</span> ((<span style=color:#902000>uint64_t</span>)hi <span style=color:#666>&lt;&lt;</span> <span style=color:#40a070>32</span>) <span style=color:#666>|</span> lo;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>As a working example, let&rsquo;s benchmark a simple add function using RDTSC:</p><div class=highlight><pre tabindex=0 style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#902000>void</span> <span style=color:#06287e>sum</span>(<span style=color:#902000>int</span><span style=color:#666>*</span> nums, <span style=color:#902000>size_t</span> n, <span style=color:#902000>int</span><span style=color:#666>*</span> res) {
</span></span><span style=display:flex><span>    <span style=color:#902000>int</span> s <span style=color:#666>=</span> <span style=color:#40a070>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>for</span> (<span style=color:#902000>size_t</span> i <span style=color:#666>=</span> <span style=color:#40a070>0</span>; i <span style=color:#666>&lt;</span> n; i<span style=color:#666>++</span>) {
</span></span><span style=display:flex><span>        s <span style=color:#666>+=</span> nums[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#666>*</span>res <span style=color:#666>=</span> s;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>To get the number of cycles a piece of code takes, we read the counter at the
start of the benchmark, then at the end:</p><div class=highlight><pre tabindex=0 style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#902000>int</span> <span style=color:#06287e>main</span>() {
</span></span><span style=display:flex><span>    <span style=color:#60a0b0;font-style:italic>// ...
</span></span></span><span style=display:flex><span><span style=color:#60a0b0;font-style:italic></span>
</span></span><span style=display:flex><span>    <span style=color:#60a0b0;font-style:italic>// benchmark
</span></span></span><span style=display:flex><span><span style=color:#60a0b0;font-style:italic></span>    <span style=color:#902000>uint64_t</span> start <span style=color:#666>=</span> <span style=color:#06287e>rdtsc</span>();
</span></span><span style=display:flex><span>    <span style=color:#06287e>sum</span>(nums, n, <span style=color:#666>&amp;</span>res);
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> end <span style=color:#666>=</span> <span style=color:#06287e>rdtsc</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#06287e>printf</span>(<span style=color:#4070a0>&#34;res=%d, cycles taken: %lu</span><span style=color:#4070a0;font-weight:700>\n</span><span style=color:#4070a0>&#34;</span>, res, (end <span style=color:#666>-</span> start));
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>return</span> <span style=color:#40a070>0</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>On my first run summing up 10,000 values, I get 13,380 cycles taken - great.</p><p>Running once more, I get 42,392 - not so great.</p><p>A couple more times I get: 37,592, 37,118, 42,028, 19,780, 42,196 - seems that
even though the values keep on wobbling with each run, there&rsquo;s a typical result.</p><p>Next step then is to comb around for how other folks address this noise
(variability in time taken) when benchmarking. Given it&rsquo;s referenced a lot, my
first go-to was Intel&rsquo;s guide on benchmarking, penned by Gabriele Paoloni [2].</p><p>Right at the start, the Paoloni points out two sources of noise when using
RDTSC:</p><ul><li>out of order execution</li><li>interrupts & preemption</li></ul><p>Let&rsquo;s start with the former:</p><h2 class=heading id=out-of-order-execution>Out of order execution
<a href=#out-of-order-execution>#</a></h2><p>Modern Intel CPU carry out out-of-order execution for instructions. From Agner
Fog&rsquo;s Software Optimization Resources [6], out-of-order execution is described
as:</p><blockquote><p>&mldr; if the execution of a particular instruction is delayed because the input
data for the instruction are not available yet, then the microprocessor will
try to find later instructions that it can do first, if the input data for the
later instructions are ready. Obviously, the microprocessor has to check if
the later instructions need the outputs from the earlier instruction.</p></blockquote><p>Since the RDTSC instruction does not rely on earlier nor on later instructions,
it can be executed entirely out-of-order way before or after the benchmark has
started/ended. Therefore, we cannot assume the measured count necessarily
represents the &lsquo;actual&rsquo; duration of the benchmark.</p><p>The Paoloni guide offers a solution - place a serializing instruction before
RDTSC. Such instructions ensure that the CPU has completed all preceding
instructions before continuing: &ldquo;all modifications to flags, registers, and
memory by previous instructions are completed, draining all buffered writes to
memory&rdquo; [8]. The serializing instruction used is CPUID which is used to retrieve
processor identification and feature information [1]. Thus, we end up with the
following pseudocode:</p><pre tabindex=0><code>Warm up instruction cache

loop N times:
    CPUID
    RDTSC - for start
    call benchmarked function
    CPUID 
    RDTSC - for end
    Record cycles (end - start)
</code></pre><p>However, the CPUID instruction takes time to execute (100-250 cycles for my CPU
per Agner Fog&rsquo;s instruction tables), and even then, the first instance might
take longer than subsequent instances. So we have to take into account its
overhead plus high variance.</p><p>The guide then offers a better approach (in terms of consistency of
measurement): use the RDTSCP instruction. It&rsquo;s similar to RDTSC in that it reads
the counter, but it also reads the CPU identifier. Of note, RDTSCP waits until
all previous instructions have been executed before reading the counter. Here&rsquo;s
the updated benchmarking pseudocode:</p><pre tabindex=0><code>Warm up instruction cache

loop N times:
    CPUID
    RDTSC - for start
    call benchmarked function
    RDTSCP - for end
    CPUID
</code></pre><p>Notice that in between getting the start and end there&rsquo;s no CPUID call. However,
the CPUID call is placed after RDTSCP since &ldquo;subsequent instructions may begin
execution before the read operation is performed&rdquo; [2]. This updated version has
lower variance - loosely speaking: you&rsquo;re more likely to get measurement values
that are closer to each other (provided you&rsquo;ve also removed other sources of
noise).</p><p>Before proceeding, it&rsquo;s worth giving a quick overview of how the guide arrives
at the &lsquo;final&rsquo; measurement value. Suppose we&rsquo;ve removed all sources of noise
(out-of-order execution, interrupts e.t.c). The steps are as follows:</p><ul><li>Loop N times storing the number of cycles taken per a given function/piece of
code. These are all the samples</li><li>Divide the N samples into M equally sized ensembles in the order they were
collected. In the code, by default, each ensemble has 100,000 values and there
are 1000 ensembles collected. Therefore N is 100,000,000. I find this number a
bit too high but I&rsquo;m guessing it&rsquo;s the price to pay for accuracy.</li><li>For each ensemble, calculate the variance and the minimum/smallest value.</li><li>If all sources of noise are eliminated, the variance of all the variances
should be zero, and the variance of minimum values across all the ensembles
should be zero.</li><li>Therefore, the minimum value across all the ensembles is the final measurement
value.</li></ul><p>From how the measurement value is determined, you can see why the author insists
that the most important characteristic of a benchmarking methodology is that it
should be completely <em>ergodic</em>. If you&rsquo;re into statistics and error analysis, I
do recommend going over the entire Paoloni guide - there&rsquo;s a lot more than I
could cover for now plus it contains the entire code listing.</p><h2 class=heading id=using-lfence-instead-of-cpuid-for-serializing-rdtsc>Using LFENCE instead of CPUID for serializing RDTSC
<a href=#using-lfence-instead-of-cpuid-for-serializing-rdtsc>#</a></h2><p>Separately, Intel&rsquo;s manual[1] does offer its own solution for serializing
RDTSC - using LFENCE and MFENCE:</p><blockquote><ul><li>If software requires RDTSC to be executed only after all previous
instructions have executed and all previous loads are globally visible, it
can execute LFENCE immediately before RDTSC.</li><li>If software requires RDTSC to be executed only after all previous
instructions have executed and all previous loads and stores are globally
visible, it can execute the sequence MFENCE;LFENCE immediately before RDTSC.</li><li>If software requires RDTSC to be executed prior to execution of any
subsequent instruction (including any memory accesses), it can execute the
sequence LFENCE immediately after RDTSC [1].</li></ul></blockquote><p>Given that the Paoloni guide is from 2010, it seems LFENCE & MFENCE (2-4 cycles)
usage is the more modern approach. Also I might be wrong here, but I don&rsquo;t think
MFENCE is necessary for my case.</p><p>Using LFENCE, we end up with the following:</p><pre tabindex=0><code>Warm up instruction cache

loop N times:
    LFENCE
    RDTSC - for start
    LFENCE

    call benchmarked function

    LFENCE
    RDTSC - for end
    LFENCE

    Record cycles (end - start)
</code></pre><p>Elsewhere, I&rsquo;ve read that compiler barriers should be added to prevent the
compiler from reordering stuff. However, in the disassembly for my code so far,
the compiler hasn&rsquo;t done anything mischievous yet to warrant compiler barriers.</p><h2 class=heading id=csapp-benchmarking-methodology>CSAPP benchmarking methodology
<a href=#csapp-benchmarking-methodology>#</a></h2><p>An alternative to the Paoloni methodology that I&rsquo;ve come across is the
<a href=https://csapp.cs.cmu.edu/3e/code.html>CSAPP</a> one that Bryant & O&rsquo;Hallaron use
throughout the code samples for their Computer Systems textbook. It still uses
RDTSC under the hood but differs in the way they pick the representative/typical
measurement value:</p><p>The benchmark involves 3 main knobs to configure:</p><ul><li><code>max_samples</code>: the max number of times to repeat the benchmark or rather, the
max number of samples to collect. By default, it&rsquo;s 500</li><li><code>k</code>: the size of the subset of the samples consisting of the smallest values
i.e. k-minimum. By default, it&rsquo;s 3</li><li><code>epsilon</code>: for determining whether the measurement values have converged. By
default, it&rsquo;s 0.05. Therefore, suppose the smallest value is 20 cycles, the
k-minimum subset can only contain values in the range of <code>[20,21]</code>, both
bounds inclusive. In general, the range of k-minimum is:
<code>[min,(1+epsilon)*min]</code>.</li></ul><p>There are other additional knobs like whether to clear the l2 cache before
benchmarking and whether to use a different counter that compensates for timer
interrupt overhead but I didn&rsquo;t look too much into those.</p><p>Once the benchmark has converged to a value, the smallest value within the
k-minimum subset is returned as the &lsquo;final&rsquo; value. However, if it runs up to max
samples and it hasn&rsquo;t converged - either there&rsquo;s too much noise, or we need to
tweak the knobs. It might even be case that the function being benchmarked
behaves quite differently given the same input (it&rsquo;s not deterministic).</p><p>Overall, CSAPP&rsquo;s benchmarking method is easier to grok and it&rsquo;s more tractable.
However, I do have some pending questions:</p><ul><li>why is the minimum considered the &lsquo;final&rsquo; value, why not something like median
or mode. The Paoloni guide also picks the minimum.
(<a href=https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/resources/lecture-10-measurement-and-timing/>Answer</a>:
compared to the mean or even the median, the minimum does best at noise
rejection)</li><li>why doesn&rsquo;t it take into account the possibility of out-of-order execution.
The code is open-source though, so I added serializing instructions to mine
just in case the processor does its thing.</li></ul><p>As an aside, CSAPP does provide the <code>ovhd</code> function for getting the counter&rsquo;s
overhead (has to be subtracted from the measurement, though I don&rsquo;t see it
getting used as much in the code samples). There&rsquo;s also the <code>mhz</code> function for
determining the clock rate of the processor, which we shall get to when
converting cycles into &lsquo;human&rsquo; time.</p><h2 class=heading id=interrupts--preemption>Interrupts & preemption
<a href=#interrupts--preemption>#</a></h2><p>Back to the Paoloni guide. Other than out-of-order execution, the author also
points out that benchmarks can be tainted by interrupts. The OS can always move
the benchmark to a different core or even preempt it entirely for a sustained
period.</p><p>The guide&rsquo;s solution is to write the benchmark as a kernel module and right
within the benchmark section, disable pre-emption and guarantee exclusive
ownership of the CPU core.</p><p>I guess I&rsquo;ll have to bite the bullet and learn kernel module programming at some
point so as to use this method though I&rsquo;m a bit hesitant for now: I don&rsquo;t want
to end up doing something really dumb and breaking my system.</p><p>For the time being, a workable solution seems to be some variant of either using
the <a href=https://man7.org/linux/man-pages/man1/taskset.1.html><code>taskset</code></a> command to
run the entire benchmark with a given CPU core affinity or to set
process/thread-level CPU affinity directly within the code using the
<code>sched_setaffinity</code> function:</p><div class=highlight><pre tabindex=0 style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;sched.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020></span>
</span></span><span style=display:flex><span><span style=color:#902000>void</span> <span style=color:#06287e>assign_to_core</span>(<span style=color:#902000>int</span> core_id) {
</span></span><span style=display:flex><span>    <span style=color:#902000>cpu_set_t</span> mask;
</span></span><span style=display:flex><span>    <span style=color:#06287e>CPU_ZERO</span>(<span style=color:#666>&amp;</span>mask);
</span></span><span style=display:flex><span>    <span style=color:#06287e>CPU_SET</span>(core_id, <span style=color:#666>&amp;</span>mask);
</span></span><span style=display:flex><span>    <span style=color:#06287e>sched_setaffinity</span>(<span style=color:#40a070>1</span>, <span style=color:#007020;font-weight:700>sizeof</span>(mask), <span style=color:#666>&amp;</span>mask);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The OS might still preempt the benchmark but at least it&rsquo;ll be pinned to the
same core. It&rsquo;s worth nothing that my specific microbenchmark was
single-threaded.</p><h2 class=heading id=converting-cycles-to-wall-time>Converting cycles to wall time
<a href=#converting-cycles-to-wall-time>#</a></h2><p>Cycles are all good, but I can&rsquo;t help but convert them into wall clock time aka
&lsquo;human&rsquo; time.</p><p>There&rsquo;s the formula:</p><pre tabindex=0><code>time taken = cycles/frequency
</code></pre><p>So we need to get RDTSC&rsquo;s frequency and plug it above.</p><p>Using the cli tool <code>dmidecode</code> to retrieve the nominal value, I get 2600 MHz
(2.6 GHz). There are two values, luckily I don&rsquo;t have to disambiguate them since
they&rsquo;re both the same :).</p><pre tabindex=0><code>$ sudo dmidecode -t processor | grep &#39;Speed&#39;
    Max Speed: 2600 MHz
    Current Speed: 2600 MHz
</code></pre><p>A different approach is to calculate the <em>approximate</em> frequency of the RDTSC
counter by using a different clock in the system. This involves calculating the
number of RDTSC cycles per a given OS wall clock duration (frequency = time
taken/cycles). CSAPP&rsquo;s <code>mhz</code> function does essentially the same thing though it
uses the <code>sleep</code> function to do the waiting (an updated version might use
<code>nanosleep</code>or <code>clock_nanosleep</code> instead).</p><p>I used the code sample below to calculate the frequency. It&rsquo;s adopted from
<a href=https://github.com/cmuratori/computer_enhance/blob/main/perfaware/part2/listing_0073_cpu_timer_guessfreq_main.cpp>here</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;stdint.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;stdio.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;time.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020>#include</span> <span style=color:#007020>&lt;x86intrin.h&gt;</span><span style=color:#007020>
</span></span></span><span style=display:flex><span><span style=color:#007020></span>
</span></span><span style=display:flex><span><span style=color:#007020;font-weight:700>static</span> <span style=color:#007020;font-weight:700>inline</span> <span style=color:#902000>uint64_t</span> <span style=color:#06287e>read_OS_timer_ns</span>(<span style=color:#902000>void</span>) {
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>struct</span> timespec now;
</span></span><span style=display:flex><span>    <span style=color:#902000>clockid_t</span> clock_id <span style=color:#666>=</span> CLOCK_MONOTONIC;
</span></span><span style=display:flex><span>    <span style=color:#06287e>clock_gettime</span>(clock_id, <span style=color:#666>&amp;</span>now);
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> now_ns <span style=color:#666>=</span> (now.tv_sec <span style=color:#666>*</span> <span style=color:#40a070>1000000000</span>) <span style=color:#666>+</span> now.tv_nsec;
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>return</span> now_ns;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#902000>double</span> <span style=color:#06287e>get_cpu_frequency_GHz</span>(<span style=color:#902000>uint64_t</span> wait_time_milliseconds) {
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> os_start_ns <span style=color:#666>=</span> <span style=color:#40a070>0</span>, os_end_ns <span style=color:#666>=</span> <span style=color:#40a070>0</span>, os_elapsed_ns <span style=color:#666>=</span> <span style=color:#40a070>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> os_wait_time_ns <span style=color:#666>=</span> wait_time_milliseconds <span style=color:#666>*</span> <span style=color:#40a070>1000000</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> cpu_start <span style=color:#666>=</span> <span style=color:#06287e>__rdtsc</span>();          <span style=color:#60a0b0;font-style:italic>// read CPU start
</span></span></span><span style=display:flex><span><span style=color:#60a0b0;font-style:italic></span>    os_start_ns        <span style=color:#666>=</span> <span style=color:#06287e>read_OS_timer_ns</span>(); <span style=color:#60a0b0;font-style:italic>// read start OS time
</span></span></span><span style=display:flex><span><span style=color:#60a0b0;font-style:italic></span>
</span></span><span style=display:flex><span>    <span style=color:#60a0b0;font-style:italic>// wait until wait_time duration is over
</span></span></span><span style=display:flex><span><span style=color:#60a0b0;font-style:italic></span>    <span style=color:#007020;font-weight:700>while</span> (os_elapsed_ns <span style=color:#666>&lt;</span> os_wait_time_ns) {
</span></span><span style=display:flex><span>        os_end_ns     <span style=color:#666>=</span> <span style=color:#06287e>read_OS_timer_ns</span>();
</span></span><span style=display:flex><span>        os_elapsed_ns <span style=color:#666>=</span> os_end_ns <span style=color:#666>-</span> os_start_ns;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> cpu_end    <span style=color:#666>=</span> <span style=color:#06287e>__rdtsc</span>();
</span></span><span style=display:flex><span>    <span style=color:#902000>uint64_t</span> cpu_cycles <span style=color:#666>=</span> cpu_end <span style=color:#666>-</span> cpu_start;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#007020;font-weight:700>return</span> (<span style=color:#902000>double</span>)cpu_cycles <span style=color:#666>/</span> (<span style=color:#902000>double</span>)os_elapsed_ns;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Setting the duration to 100 milliseconds, I got frequencies hovering around
2.5925 GHz. Not quite 2.6 GHz but I&rsquo;ll choke it off to clock precision and
various overheads here and there.</p><p>Elsewhere, I&rsquo;ve read that one should check the kernel logs to retrieve the
actual RDTSC frequency. Interestingly, using this method, I get 3 different
values when grepping the the <code>dmesg</code> kernel logs:</p><pre tabindex=0><code>$ sudo dmesg | grep &#39;.*tsc.*MHz&#39;
[    0.000000] tsc: Detected 2600.000 MHz processor
[    0.000000] tsc: Detected 2599.992 MHz TSC
[    1.682221] tsc: Refined TSC clocksource calibration: 2592.001 MHz
</code></pre><p>And from the <code>turbostat</code> command:</p><pre tabindex=0><code>$ sudo turbostat --num_iterations 1 --interval 1
TSC: 2592 MHz (24000000 Hz * 216 / 2 / 1000000)
CPUID(0x16): base_mhz: 2600 max_mhz: 5000 bus_mhz: 100
</code></pre><p>There seems to be a base/processor frequency and a TSC frequency and both are
quite close though not quite equal. Anyway, since I was doing the conversion to
wall clock time as a final reporting step, I decided to go with the calculated
approximate value (2.5925).</p><h2 class=heading id=conclusion-down-the-systems-rabbit-hole>Conclusion: Down the Systems Rabbit Hole
<a href=#conclusion-down-the-systems-rabbit-hole>#</a></h2><p>The running theme so far has been that without accounting for how some
lower-level component actually works, whether it&rsquo;s the CPU&rsquo;s out-of-order
execution or interrupts caused by the OS, we risk deriving erroneous values.</p><p>So far, I&rsquo;ve only scratched the surface. To make microbenchmarking measurements
sensible, there&rsquo;s a lot more that we&rsquo;ve got to account for:</p><ol><li><strong>BIOS Settings</strong> - Paoloni mentions that BIOS settings have to be optimized
to remove all factors that could cause indeterminism, though he doesn&rsquo;t
specifier which ones - some could be peculiar to his computer.</li><li><strong>Hyperthreading</strong>: CPUs can run two threads on the same physical cores with
both sharing the same L1 and L2 cache. It&rsquo;s recommended to turn off
hyperthreading when benchmarking so as to increase reproducibility [2].</li><li><strong>CPU Power management</strong>: Core frequencies can be lowered or even paused
entirely to reduce temperature and power consumption. This should also be
disabled when benchmarking - for the same reasons [2].</li><li><strong>Turbo boost</strong>: Given CPU-intensive workloads - Intel CPUs can increase
frequency way above the nominal value. Once more, this should be disabled
when benchmarking [2]. An implication of both this point and the previous one
is that the actual frequency of our program varies throughout its lifetime -
even though the TSC frequency remains invariant.</li><li><strong>Cache effects</strong>: Code might run slower the first time due to cache misses.
Both the CSAPP and Paoloni code involve some warm up steps for both
instructions and data to reduce variability.</li><li><strong>Program&rsquo;s memory layout</strong>. Turns out the link order, environment variables
and even the directory from which we run our program can cause our code to
run slower/faster than it should (as detailed in Mytkowicz et al&rsquo;s paper
<a href=https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf>&lsquo;Producing Wrong Data Without Doing Anything Obviously Wrong!&rsquo;</a>).
All these change the layout of a program once it&rsquo;s loaded which in turn
affects caching, TLB lookups, prefetching & branch predictions. To derive
meaningful benchmark results, Charlie Curtsinger and Emery D. Berger propose
<a href=https://people.cs.umass.edu/~emery/pubs/stabilizer-asplos13.pdf>Stabilizer</a>,
a tool that repeatedly randomizes a program&rsquo;s memory layout so to eliminate
its effect in measurements. Emery has a great intro on how Stabilier works in
his 2019 Strange Loop talk
<a href="https://www.youtube.com/watch?v=r-TLSBdHe1A">&lsquo;Performance Matters&rsquo;</a>.</li><li><strong>Correctness</strong>: this should go without mentioning but as Tim Harris points
out in
<a href=https://timharris.uk/misc/five-ways.pdf>Five ways not to fool yourself</a>,
incorrect algorithms are often fast. One might place lightweight correctness
checks throughout the code or even as a post-benchmarking step.</li><li><strong>Configuration</strong>: Ideally, this should fall under correctness but it&rsquo;s worth
having it as its own separate point - after all
<a href=https://blog.acolyer.org/2016/11/29/early-detection-of-configuration-errors-to-reduce-failure-damage/>configuration mishaps do cause a huge chunk of production failures</a>.
Values used in execution should match the configuration values, or better
yet, as Tim Harris recommends, always collect values from the execution
rather than from the config - it&rsquo;ll be easier to spot any mismatch that
arises [9].</li><li><strong>The &lsquo;overall&rsquo; system</strong> - Gernot Heiser puts it best in
<a href=http://gernot-heiser.org/benchmarking-crimes.html#ubm>System Benchmarking Crimes</a>:
&ldquo;Micro-benchmarks specifically probe a particular aspect of a system. Even if
they are very comprehensive, they will not be representative of overall
system performance. Macro-benchmarks (representing real-world workloads) must
be used to provide a realistic picture of overall performance&rdquo;. The least we
can do when carrying out microbenchmarks is to ensure the workloads are
meaningful and represent production settings. On a similar note, Curtsinger &
Emery Berger created <a href=https://github.com/plasma-umass/coz>Coz</a> - a causal
profiling tool that narrows down which parts of the codebase ought to be
optimized in order to actually increase overall performance. The &lsquo;Performance
Matters&rsquo; video also goes over Coz in the second half.</li><li><strong>Actual audible noise</strong> -
<a href="https://www.youtube.com/watch?v=tDacjrSCeq4">shouting at your hard disk makes it slower X`D</a>,
please don&rsquo;t.</li></ol><p>Even with benchmarking, you can see why computer science programs have some
mandatory systems classes and even self-taught programmers are
<a href=https://teachyourselfcs.com/>highly encouraged</a> to learn systems development.
A lot of these stuff won&rsquo;t directly apply to day-to-day programming but code
doesn&rsquo;t run on abstract machines - all software ultimately runs on systems (well
duh) and it&rsquo;s worth understanding the foundations upon which we&rsquo;re building on.</p><h2 class=heading id=references--further-reading>References & Further Reading
<a href=#references--further-reading>#</a></h2><ol><li><a href=https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html>Intel® 64 and IA-32 Architectures Software Developer Manuals</a></li><li>How to Benchmark Code Execution Times in Intel IA-32 and IA-64 Instruction
Set Architectures - Gabriele Paoloni - September 2010</li><li><a href=https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go>How to write benchmarks in Go - Dave Cheney</a></li><li><a href=https://events.it4i.cz/event/39/attachments/150/349/09-2020-01-30_MSR_SAFE.pdf>MSR & MSR_FASE - Energy Efficiency in HPC - PTC Lecture slide - pdf</a></li><li><a href=https://stackoverflow.com/questions/13772567/how-to-get-the-cpu-cycle-count-in-x86-64-from-c>How to get the CPU cycle count in x86_64 from C++? - StackOverflow</a></li><li><a href=https://www.agner.org/optimize/microarchitecture.pdf>The microarchitecture of Intel, AMD and VIA CPUs - Agner Fog - Software Optimization Resources - pdf</a></li><li><a href=https://sites.utexas.edu/jdm4372/2018/07/23/comments-on-timing-short-code-sections-on-intel-processors/>Comments on timing short code sections on Intel processors - John McCalpin -
blog</a></li><li><a href=https://www.felixcloutier.com/x86/serialize>SERIALIZE - serialize instruction execution - Felix Cloutier - x86 and amd64 instruction reference - derived from Intel&rsquo;s</a></li><li><a href=https://timharris.uk/misc/five-ways.pdf>Five ways not to fool yourself - Tim Harris - pdf</a></li><li><a href=https://sled.rs/perf.html>sled theoretical performance guide - Tyler Neely</a></li><li><a href=https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf>Producing Wrong Data Without Doing Anything Obviously Wrong! - Mytkowicz et al - pdf</a>&rsquo;).</li><li><a href=https://people.cs.umass.edu/~emery/pubs/stabilizer-asplos13.pdf>Stabilizer - Charlie Curtsinger, Emery D. Berger - pdf</a>,</li><li><a href="https://www.youtube.com/watch?v=r-TLSBdHe1A">Performance Matters - Emery Berger - Video</a></li><li><a href=https://github.com/plasma-umass/coz>Coz: Finding Code that Counts - Charlie Curtsinger, Emery D. Berger</a></li><li><a href=http://gernot-heiser.org/benchmarking-crimes.html>System Benchmarking Crimes - Gernot Heiser</a></li></ol></div><div class=single-pagination><hr><div class=flex><div class=single-pagination-next><div class=single-pagination-container-next><div class=single-pagination-text>←</div><div class=single-pagination-text><a href=/p/mem-cache-details/>Retrieving Memory and Cache Organization</a></div></div></div><div class=single-pagination-prev><div class=single-pagination-container-prev><div class=single-pagination-text><a href=/p/logging/>Logging in Go</a></div><div class=single-pagination-text>→</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>&mldr;</p></footer><script async src=https://scripts.simpleanalyticscdn.com/latest.js></script></body><script>function isAuto(){return document.body.classList.contains("auto")}function setTheme(){if(!isAuto())return;document.body.classList.remove("auto");let e="light";window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(e="dark"),document.body.classList.add(e)}function invertBody(){document.body.classList.toggle("dark"),document.body.classList.toggle("light")}isAuto()&&window.matchMedia("(prefers-color-scheme: dark)").addListener(invertBody),setTheme()</script></html>