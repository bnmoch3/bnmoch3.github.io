<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://bnm3k.github.io//favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bnm3k.github.io//favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://bnm3k.github.io//favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://bnm3k.github.io//android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://bnm3k.github.io//apple-touch-icon.png><meta name=description content><title>Virtual Memory Hot/Cold Data Re-organization for OLTP | bnm 3000
</title><link rel=canonical href=https://bnm3k.github.io/blog/efficient-os-paging-hot-cold-db/><meta property="og:url" content="https://bnm3k.github.io/blog/efficient-os-paging-hot-cold-db/"><meta property="og:site_name" content="bnm 3000"><meta property="og:title" content="Virtual Memory Hot/Cold Data Re-organization for OLTP"><meta property="og:description" content="Hot/Cold aware memory allocation with locking of the hot region to physical memory and letting the OS swap out cold LRU pages as needed."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2024-06-07T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-07T00:00:00+00:00"><meta property="article:tag" content="Database Internals"><link rel=stylesheet href=/assets/combined.min.186794b3399a702d3092949042cdc215dea303c17e71e7c0254768448de11db8.css media=all></head><body class=light><div class=content><header><div class=header><div class=flex><p class=small><a href=/>/home</a></p><p class=small><a href=/posts>/posts</a></p><p class=small><a href=/notes>/notes</a></p><p class=small><a href=/tags>/tags</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>Home</a>
<span class=breadcrumbs-separator>> </span><a href=/notes/>Notes</a>
<span class=breadcrumbs-separator>> </span><a class=breadcrumbs-current href=/blog/efficient-os-paging-hot-cold-db/>Virtual Memory Hot/Cold Data Re-organization for OLTP</a></div><div><div class=single-intro-container><h1 class=single-title>Virtual Memory Hot/Cold Data Re-organization for OLTP</h1><p class=single-readtime><time datetime=2024-06-07T00:00:00+00:00>June 7, 2024</time>
&nbsp; · &nbsp;
4 min read</p></div><div class=single-content><p>The problem: In OLTP databases designed for main-memory, the datasets might
exceed the main memory capacity. Bringing back a disk-oriented architecture
fixes this problem, though at the cost of increased complexity and reduced
performance: &ldquo;DBMS engines optimized for in-memory processing have no knowledge
of secondary storage. Traditional storage optimizations, such as the buffer pool
abstraction, the page organization, certain data structures (e.g. B-Trees), and
ARIES-style logging are explicitly discarded in order to reduce overhead&rdquo; [1].</p><p>A simpler solution which involves doing nothing is to rely on the OS&rsquo;s default
paging. However it is sub-optimal since the OS can only use coarse-grained
metrics to determine what to keep in-memory and what to page out.</p><p>To demonstrate the performance impact on relying on the default OS paging
approach, the authors carry out an experiment whereby the working set&rsquo;s size is
fixed and can fit in memory. Once the dataset exceeds main-memory, query
processing throughput decreases as OS paging kicks in. The throughput decrease
is more severe in instances where the RAM size is smaller.</p><p>Figure from [1]:</p><p><figure><div><img loading=lazy alt="figure 1" src=/blog/efficient-os-paging-hot-cold-db/images/figure_1.png width=1108px height=813px></div></figure></p><p>The authors instead propose a smarter way to rely on OS paging: given that most
if not all OLTP workloads tend to exhibit skew whereby some records are hot and
most records are cold, the database should partition virtual memory into a hot
region and a cold region. The hot region remains/is locked to in-memory (the OS
is not allowed to page it out) and as for the cold region, the OS is free to
swap out LRU resident regions whenever a query accesses a cold paged out tuple.</p><h2 class=heading id=data-reorganization>Data-Reorganization
<a href=#data-reorganization>#</a></h2><p>Step-by-step, the authors&rsquo; solution is as follows:</p><p>Figure from [1]:</p><p><figure><div><img loading=lazy alt="figure 2" src=/blog/efficient-os-paging-hot-cold-db/images/figure_2_system_architecture.png width=1250px height=840px></div></figure></p><ol><li><strong>Sample accesses</strong>: log every tuple access into a circular buffer per a
given sampling frequency. A log entry should include the tuple ID and its
current classification (hot or cold).</li><li><strong>Write access logs</strong>: the logs are written either to a file or to a network.
For performance reasons, the writer is decoupled from the critical path of
query execution. If the writer is slow, the sampling frequency decreases
(more log entries are dropped).</li><li><strong>Process access logs</strong>: Ideally in a different server, compute the access
frequencies from the access trace: hot tuples that aren&rsquo;t getting accessed as
often are re-categorized as cold and cold tuples that are now getting
accessed a lot more are re-categorized as hot [2]. Furthermore, each table is
assigned a computed <em>memory budget</em> i.e. the size for its hot region. For the
sake of comparison, if you recall in the
<a href=/blog/anti-caching>anticaching approach</a>, the memory budget for a table is
determined dynamically by how much it&rsquo;s been accessed since the last round of
evictions: the more a table is accessed, the less the data that&rsquo;s evicted
from it and vice versa.</li><li><strong>Read optimal tuple placement</strong>: via a dedicated thread once step 3 is
complete.</li><li><strong>Re-organization</strong>: Using a hot-cold aware malloc, delete and re-insert
tuples whose status has changed. By hot-cold aware, this means that if the
tuple is hot, malloc will allocate memory for it in the hot region, same as
with cold tuples. The high-level delete/re-insert is necessary to keep all
indices consistent, plus we get to reuse code. It&rsquo;s worth noting that the hot
region is &rsquo;locked&rsquo; to memory to prevent the OS from swapping it out [3].</li></ol><p>To evaluate this approach, the authors carry out a couple of experiments. I&rsquo;ll
highlight the first one which involves a modified TPC-C benchmark. There are
three cases:</p><ul><li>entire database is in memory (allocated 64 GB)</li><li>default OS paging: database restricted to 5GB of main memory</li><li>data-reorganization: database restricted to 5GB of main memory</li></ul><p>Figure from [1]:</p><p><figure><div><img loading=lazy alt="figure 4" src=/blog/efficient-os-paging-hot-cold-db/images/figure_4.png width=816px height=568px></div></figure></p><p>From the paper: &ldquo;the hot/cold data separation stabilizes throughput within 7% of
the in-memory performance, although the actual data stored grows 50x larger than
the amount of RAM available. On the other hand, the throughput of the unmodified
engine drops by 66% when swapping to the SSD&rdquo;.</p><p>Overall, this approach seems relatively simple since much of the heavy-lifting
is left to the OS. One aspect I&rsquo;d have wished for the authors to dig deeper into
is when data-reorganization should be triggered - which exact metrics are
measured and what thresholds are used. Also, does data-reorganization handle
only the case where all tuples in a relation have the same size - if otherwise,
I suppose it&rsquo;ll be much closer to a full-on seperate malloc implementation.
There&rsquo;s also
<a href=https://www.cs.cit.tum.de/fileadmin/w00cfj/dis/_my_direct_uploads/vmcache.pdf>vmcache</a>
which can be used to let the system have greater control over page faulting and
eviction which then provides the option for abort-and-restart if a transaction
accesses an evicted page.</p><h2 class=heading id=references>References
<a href=#references>#</a></h2><ol><li><a href=https://dl.acm.org/doi/10.1145/2485278.2485285>Enabling Efficient OS Paging for Main-Memory OLTP Databases - Radu Stoica,
Anastasia Ailamaki</a></li><li><a href=https://www.microsoft.com/en-us/research/wp-content/uploads/2013/04/ColdDataClassification-icde2013-cr.pdf>Efficient hot/cold categorizing Identifying Hot and Cold data in Main-Memory
Databases - Justin J. Levandoski, Per-Ake Larson, Radu Stoica</a></li><li><a href=https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/reference_guide/using_mlock_to_avoid_page_io>Using mlock to Avoid Page I/O - Redhat Reference Guide</a></li></ol></div><div class=single-pagination><hr><div class=flex><div class=single-pagination-next><div class=single-pagination-container-next><div class=single-pagination-text>←</div><div class=single-pagination-text><a href=/blog/hyper-compaction/>Compacting Transactional Data in HyPer</a></div></div></div><div class=single-pagination-prev><div class=single-pagination-container-prev><div class=single-pagination-text><a href=/blog/project-siberia-hot-cold-id/>Offline (but Faster and more Accurate) Classification of Hot and Cold Data</a></div><div class=single-pagination-text>→</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>&mldr;</p></footer></body><script>function isAuto(){return document.body.classList.contains("auto")}function setTheme(){if(!isAuto())return;document.body.classList.remove("auto");let e="light";window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(e="dark"),document.body.classList.add(e)}function invertBody(){document.body.classList.toggle("dark"),document.body.classList.toggle("light")}isAuto()&&window.matchMedia("(prefers-color-scheme: dark)").addListener(invertBody),setTheme()</script></html>